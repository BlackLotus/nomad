apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "nomad.fullname" . }}-worker
  labels:
    app.kubernetes.io/name: {{ include "nomad.name" . }}-worker
    helm.sh/chart: {{ include "nomad.chart" . }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  replicas: {{ .Values.worker.replicas }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "nomad.name" . }}-worker
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ include "nomad.name" . }}-worker
        app.kubernetes.io/instance: {{ .Release.Name }}
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: {{ include "nomad.name" . }}-worker
                app.kubernetes.io/instance: {{ .Release.Name }}
      containers:
      - name: {{ include "nomad.name" . }}-worker
        image: "{{ .Values.images.nomad.name }}:{{ .Values.images.nomad.tag }}"
        resources:
          limits:
            memory: "{{ .Values.worker.memlimit }}Gi"
          requests:
            memory: "{{ .Values.worker.memrequest }}Gi"
        volumeMounts:
        - mountPath: /app/nomad.yaml
          name: nomad-conf
          subPath: nomad.yaml
        - mountPath: /app/.volumes/fs/public
          name: public-volume
        - mountPath: /app/.volumes/fs/staging
          name: staging-volume
        - mountPath: /app/.volumes/fs/extracted
          name: extracted-volume
        - mountPath: /nomad
          name: nomad-volume
        env:
        - name: NOMAD_SERVICE
          value: "worker"
        - name: NOMAD_CONSOLE_LOG_LEVEL
          value: "{{ .Values.worker.console_loglevel }}"
        - name: NOMAD_LOGSTASH_LEVEL
          value: "{{ .Values.worker.logstash_loglevel }}"
        - name: NOMAD_CELERY_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        command: ["python", "-m", "celery", "worker", "-A", "nomad.processing", "-n", "$(NOMAD_CELERY_NODE_NAME)"]
        livenessProbe:
          exec:
            command:
            - bash
            - -c
            - NOMAD_LOGSTASH_LEVEL=WARNING python -m celery -A nomad.processing status | grep "$(NOMAD_CELERY_NODE_NAME):.*OK"
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - bash
            - -c
            - NOMAD_LOGSTASH_LEVEL=WARNING python -m celery -A nomad.processing status | grep "${NOMAD_CELERY_NODE_NAME}:.*OK"
          initialDelaySeconds: 5
          periodSeconds: 120
      nodeSelector:
        nomadtype: worker
      imagePullSecrets:
      - name: {{ .Values.images.secret }}
      imagePullPolicy: always
      volumes:
      - name: nomad-conf
        configMap:
          name: {{ include "nomad.fullname" . }}-configmap
      - name: public-volume
        hostPath:
          path: {{ .Values.volumes.public }}
          type: Directory
      - name: extracted-volume
        hostPath:
          path: {{ .Values.volumes.extracted }}
          type: Directory
      - name: staging-volume
        {{ if (eq .Values.worker.storage "memory") }}
        emptyDir:
          medium: 'Memory'
        {{ else }}
        hostPath:
          path: {{ .Values.volumes.staging}}
          type: Directory
        {{ end }}
      - name: nomad-volume
        hostPath:
          path: {{ .Values.volumes.nomad }}
          type: Directory
